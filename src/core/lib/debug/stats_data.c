/*
 * Copyright 2017 gRPC authors.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/*
 * Automatically generated by tools/codegen/core/gen_stats_data.py
 */

#include "src/core/lib/debug/stats_data.h"
#include <grpc/support/useful.h>
#include "src/core/lib/debug/stats.h"
#include "src/core/lib/iomgr/exec_ctx.h"
const char *grpc_stats_counter_name[GRPC_STATS_COUNTER_COUNT] = {
    "client_calls_created",
    "server_calls_created",
    "cqs_created",
    "client_channels_created",
    "client_subchannels_created",
    "server_channels_created",
    "syscall_poll",
    "syscall_wait",
    "histogram_slow_lookups",
    "syscall_write",
    "syscall_read",
    "tcp_backup_pollers_created",
    "tcp_backup_poller_polls",
    "http2_op_batches",
    "http2_op_cancel",
    "http2_op_send_initial_metadata",
    "http2_op_send_message",
    "http2_op_send_trailing_metadata",
    "http2_op_recv_initial_metadata",
    "http2_op_recv_message",
    "http2_op_recv_trailing_metadata",
    "http2_settings_writes",
    "http2_pings_sent",
    "http2_writes_begun",
    "http2_writes_offloaded",
    "http2_writes_continued",
    "http2_partial_writes",
    "http2_initiate_write_due_to_initial_write",
    "http2_initiate_write_due_to_start_new_stream",
    "http2_initiate_write_due_to_send_message",
    "http2_initiate_write_due_to_send_initial_metadata",
    "http2_initiate_write_due_to_send_trailing_metadata",
    "http2_initiate_write_due_to_retry_send_ping",
    "http2_initiate_write_due_to_continue_pings",
    "http2_initiate_write_due_to_goaway_sent",
    "http2_initiate_write_due_to_rst_stream",
    "http2_initiate_write_due_to_close_from_api",
    "http2_initiate_write_due_to_stream_flow_control",
    "http2_initiate_write_due_to_transport_flow_control",
    "http2_initiate_write_due_to_send_settings",
    "http2_initiate_write_due_to_bdp_estimator_ping",
    "http2_initiate_write_due_to_flow_control_unstalled_by_setting",
    "http2_initiate_write_due_to_flow_control_unstalled_by_update",
    "http2_initiate_write_due_to_application_ping",
    "http2_initiate_write_due_to_keepalive_ping",
    "http2_initiate_write_due_to_transport_flow_control_unstalled",
    "http2_initiate_write_due_to_ping_response",
    "http2_initiate_write_due_to_force_rst_stream",
    "combiner_locks_initiated",
    "combiner_locks_scheduled_items",
    "combiner_locks_scheduled_final_items",
    "combiner_locks_offloaded",
    "executor_scheduled_short_items",
    "executor_scheduled_long_items",
    "executor_scheduled_to_self",
    "executor_wakeup_initiated",
    "executor_queue_drained",
    "executor_push_retries",
    "executor_threads_created",
    "executor_threads_used",
    "server_requested_calls",
    "server_slowpath_requests_queued",
};
const char *grpc_stats_counter_doc[GRPC_STATS_COUNTER_COUNT] = {
    "Number of client side calls created by this process",
    "Number of server side calls created by this process",
    "Number of completion queues created", "Number of client channels created",
    "Number of client subchannels created", "Number of server channels created",
    "Number of polling syscalls (epoll_wait, poll, etc) made by this process",
    "Number of sleeping syscalls made by this process",
    "Number of times histogram increments went through the slow (binary "
    "search) path",
    "Number of write syscalls (or equivalent - eg sendmsg) made by this "
    "process",
    "Number of read syscalls (or equivalent - eg recvmsg) made by this process",
    "Number of times a backup poller has been created (this can be expensive)",
    "Number of polls performed on the backup poller",
    "Number of batches received by HTTP2 transport",
    "Number of cancelations received by HTTP2 transport",
    "Number of batches containing send initial metadata",
    "Number of batches containing send message",
    "Number of batches containing send trailing metadata",
    "Number of batches containing receive initial metadata",
    "Number of batches containing receive message",
    "Number of batches containing receive trailing metadata",
    "Number of settings frames sent", "Number of HTTP2 pings sent by process",
    "Number of HTTP2 writes initiated",
    "Number of HTTP2 writes offloaded to the executor from application threads",
    "Number of HTTP2 writes that finished seeing more data needed to be "
    "written",
    "Number of HTTP2 writes that were made knowing there was still more data "
    "to be written (we cap maximum write size to syscall_write)",
    "Number of HTTP2 writes initiated due to 'initial_write'",
    "Number of HTTP2 writes initiated due to 'start_new_stream'",
    "Number of HTTP2 writes initiated due to 'send_message'",
    "Number of HTTP2 writes initiated due to 'send_initial_metadata'",
    "Number of HTTP2 writes initiated due to 'send_trailing_metadata'",
    "Number of HTTP2 writes initiated due to 'retry_send_ping'",
    "Number of HTTP2 writes initiated due to 'continue_pings'",
    "Number of HTTP2 writes initiated due to 'goaway_sent'",
    "Number of HTTP2 writes initiated due to 'rst_stream'",
    "Number of HTTP2 writes initiated due to 'close_from_api'",
    "Number of HTTP2 writes initiated due to 'stream_flow_control'",
    "Number of HTTP2 writes initiated due to 'transport_flow_control'",
    "Number of HTTP2 writes initiated due to 'send_settings'",
    "Number of HTTP2 writes initiated due to 'bdp_estimator_ping'",
    "Number of HTTP2 writes initiated due to "
    "'flow_control_unstalled_by_setting'",
    "Number of HTTP2 writes initiated due to "
    "'flow_control_unstalled_by_update'",
    "Number of HTTP2 writes initiated due to 'application_ping'",
    "Number of HTTP2 writes initiated due to 'keepalive_ping'",
    "Number of HTTP2 writes initiated due to "
    "'transport_flow_control_unstalled'",
    "Number of HTTP2 writes initiated due to 'ping_response'",
    "Number of HTTP2 writes initiated due to 'force_rst_stream'",
    "Number of combiner lock entries by process (first items queued to a "
    "combiner)",
    "Number of items scheduled against combiner locks",
    "Number of final items scheduled against combiner locks",
    "Number of combiner locks offloaded to different threads",
    "Number of finite runtime closures scheduled against the executor (gRPC "
    "thread pool)",
    "Number of potentially infinite runtime closures scheduled against the "
    "executor (gRPC thread pool)",
    "Number of closures scheduled by the executor to the executor",
    "Number of thread wakeups initiated within the executor",
    "Number of times an executor queue was drained",
    "Number of times we raced and were forced to retry pushing a closure to "
    "the executor",
    "Size of the backing thread pool for overflow gRPC Core work",
    "How many executor threads actually got used",
    "How many calls were requested (not necessarily received) by the server",
    "How many times was the server slow path taken (indicates too few "
    "outstanding requests)",
};
const char *grpc_stats_histogram_name[GRPC_STATS_HISTOGRAM_COUNT] = {
    "tcp_write_size",
    "tcp_write_iov_size",
    "tcp_read_size",
    "tcp_read_offer",
    "tcp_read_offer_iov_size",
    "http2_send_message_size",
    "http2_send_initial_metadata_per_write",
    "http2_send_message_per_write",
    "http2_send_trailing_metadata_per_write",
    "http2_send_flowctl_per_write",
    "executor_closures_per_wakeup",
    "server_cqs_checked",
};
const char *grpc_stats_histogram_doc[GRPC_STATS_HISTOGRAM_COUNT] = {
    "Number of bytes offered to each syscall_write",
    "Number of byte segments offered to each syscall_write",
    "Number of bytes received by each syscall_read",
    "Number of bytes offered to each syscall_read",
    "Number of byte segments offered to each syscall_read",
    "Size of messages received by HTTP2 transport",
    "Number of streams initiated written per TCP write",
    "Number of streams whose payload was written per TCP write",
    "Number of streams terminated per TCP write",
    "Number of flow control updates written per TCP write",
    "Number of closures executed each time an executor wakes up",
    "How many completion queues were checked looking for a CQ that had "
    "requested the incoming call",
};
const int grpc_stats_table_0[65] = {
    0,       1,       2,       3,       4,       6,       8,        11,
    15,      20,      26,      34,      44,      57,      73,       94,
    121,     155,     199,     255,     327,     419,     537,      688,
    881,     1128,    1444,    1848,    2365,    3026,    3872,     4954,
    6338,    8108,    10373,   13270,   16976,   21717,   27782,    35541,
    45467,   58165,   74409,   95189,   121772,  155778,  199281,   254933,
    326126,  417200,  533707,  682750,  873414,  1117323, 1429345,  1828502,
    2339127, 2992348, 3827987, 4896985, 6264509, 8013925, 10251880, 13114801,
    16777216};
const uint8_t grpc_stats_table_1[87] = {
    0,  0,  1,  1,  2,  3,  3,  4,  4,  5,  6,  6,  7,  8,  8,  9,  10, 11,
    11, 12, 13, 13, 14, 15, 15, 16, 17, 17, 18, 19, 20, 20, 21, 22, 22, 23,
    24, 25, 25, 26, 27, 27, 28, 29, 29, 30, 31, 31, 32, 33, 34, 34, 35, 36,
    36, 37, 38, 39, 39, 40, 41, 41, 42, 43, 44, 44, 45, 45, 46, 47, 48, 48,
    49, 50, 51, 51, 52, 53, 53, 54, 55, 56, 56, 57, 58, 58, 59};
const int grpc_stats_table_2[65] = {
    0,   1,   2,   3,   4,   5,   6,   7,   8,   9,   10,  11,  12,
    14,  16,  18,  20,  22,  24,  27,  30,  33,  36,  39,  43,  47,
    51,  56,  61,  66,  72,  78,  85,  92,  100, 109, 118, 128, 139,
    151, 164, 178, 193, 209, 226, 244, 264, 285, 308, 333, 359, 387,
    418, 451, 486, 524, 565, 609, 656, 707, 762, 821, 884, 952, 1024};
const uint8_t grpc_stats_table_3[102] = {
    0,  0,  0,  1,  1,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,
    6,  7,  7,  7,  8,  8,  9,  9,  10, 11, 11, 12, 12, 13, 13, 14, 14,
    14, 15, 15, 16, 16, 17, 17, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23,
    23, 24, 24, 24, 25, 26, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 32,
    32, 33, 33, 34, 35, 35, 36, 37, 37, 38, 38, 39, 39, 40, 40, 41, 41,
    42, 42, 43, 44, 44, 45, 46, 46, 47, 48, 48, 49, 49, 50, 50, 51, 51};
const int grpc_stats_table_4[9] = {0, 1, 2, 4, 7, 13, 23, 39, 64};
const uint8_t grpc_stats_table_5[9] = {0, 0, 1, 2, 2, 3, 4, 4, 5};
void grpc_stats_inc_tcp_write_size(grpc_exec_ctx *exec_ctx, int value) {
  value = GPR_CLAMP(value, 0, 16777216);
  if (value < 5) {
    GRPC_STATS_INC_HISTOGRAM((exec_ctx), GRPC_STATS_HISTOGRAM_TCP_WRITE_SIZE,
                             value);
    return;
  }
  union {
    double dbl;
    uint64_t uint;
  } _val, _bkt;
  _val.dbl = value;
  if (_val.uint < 4683743612465315840ull) {
    int bucket =
        grpc_stats_table_1[((_val.uint - 4617315517961601024ull) >> 50)] + 5;
    _bkt.dbl = grpc_stats_table_0[bucket];
    bucket -= (_val.uint < _bkt.uint);
    GRPC_STATS_INC_HISTOGRAM((exec_ctx), GRPC_STATS_HISTOGRAM_TCP_WRITE_SIZE,
                             bucket);
    return;
  }
  GRPC_STATS_INC_HISTOGRAM((exec_ctx), GRPC_STATS_HISTOGRAM_TCP_WRITE_SIZE,
                           grpc_stats_histo_find_bucket_slow(
                               (exec_ctx), value, grpc_stats_table_0, 64));
}
void grpc_stats_inc_tcp_write_iov_size(grpc_exec_ctx *exec_ctx, int value) {
  value = GPR_CLAMP(value, 0, 1024);
  if (value < 13) {
    GRPC_STATS_INC_HISTOGRAM((exec_ctx),
                             GRPC_STATS_HISTOGRAM_TCP_WRITE_IOV_SIZE, value);
    return;
  }
  union {
    double dbl;
    uint64_t uint;
  } _val, _bkt;
  _val.dbl = value;
  if (_val.uint < 4637863191261478912ull) {
    int bucket =
        grpc_stats_table_3[((_val.uint - 4623507967449235456ull) >> 48)] + 13;
    _bkt.dbl = grpc_stats_table_2[bucket];
    bucket -= (_val.uint < _bkt.uint);
    GRPC_STATS_INC_HISTOGRAM((exec_ctx),
                             GRPC_STATS_HISTOGRAM_TCP_WRITE_IOV_SIZE, bucket);
    return;
  }
  GRPC_STATS_INC_HISTOGRAM((exec_ctx), GRPC_STATS_HISTOGRAM_TCP_WRITE_IOV_SIZE,
                           grpc_stats_histo_find_bucket_slow(
                               (exec_ctx), value, grpc_stats_table_2, 64));
}
void grpc_stats_inc_tcp_read_size(grpc_exec_ctx *exec_ctx, int value) {
  value = GPR_CLAMP(value, 0, 16777216);
  if (value < 5) {
    GRPC_STATS_INC_HISTOGRAM((exec_ctx), GRPC_STATS_HISTOGRAM_TCP_READ_SIZE,
                             value);
    return;
  }
  union {
    double dbl;
    uint64_t uint;
  } _val, _bkt;
  _val.dbl = value;
  if (_val.uint < 4683743612465315840ull) {
    int bucket =
        grpc_stats_table_1[((_val.uint - 4617315517961601024ull) >> 50)] + 5;
    _bkt.dbl = grpc_stats_table_0[bucket];
    bucket -= (_val.uint < _bkt.uint);
    GRPC_STATS_INC_HISTOGRAM((exec_ctx), GRPC_STATS_HISTOGRAM_TCP_READ_SIZE,
                             bucket);
    return;
  }
  GRPC_STATS_INC_HISTOGRAM((exec_ctx), GRPC_STATS_HISTOGRAM_TCP_READ_SIZE,
                           grpc_stats_histo_find_bucket_slow(
                               (exec_ctx), value, grpc_stats_table_0, 64));
}
void grpc_stats_inc_tcp_read_offer(grpc_exec_ctx *exec_ctx, int value) {
  value = GPR_CLAMP(value, 0, 16777216);
  if (value < 5) {
    GRPC_STATS_INC_HISTOGRAM((exec_ctx), GRPC_STATS_HISTOGRAM_TCP_READ_OFFER,
                             value);
    return;
  }
  union {
    double dbl;
    uint64_t uint;
  } _val, _bkt;
  _val.dbl = value;
  if (_val.uint < 4683743612465315840ull) {
    int bucket =
        grpc_stats_table_1[((_val.uint - 4617315517961601024ull) >> 50)] + 5;
    _bkt.dbl = grpc_stats_table_0[bucket];
    bucket -= (_val.uint < _bkt.uint);
    GRPC_STATS_INC_HISTOGRAM((exec_ctx), GRPC_STATS_HISTOGRAM_TCP_READ_OFFER,
                             bucket);
    return;
  }
  GRPC_STATS_INC_HISTOGRAM((exec_ctx), GRPC_STATS_HISTOGRAM_TCP_READ_OFFER,
                           grpc_stats_histo_find_bucket_slow(
                               (exec_ctx), value, grpc_stats_table_0, 64));
}
void grpc_stats_inc_tcp_read_offer_iov_size(grpc_exec_ctx *exec_ctx,
                                            int value) {
  value = GPR_CLAMP(value, 0, 1024);
  if (value < 13) {
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_TCP_READ_OFFER_IOV_SIZE, value);
    return;
  }
  union {
    double dbl;
    uint64_t uint;
  } _val, _bkt;
  _val.dbl = value;
  if (_val.uint < 4637863191261478912ull) {
    int bucket =
        grpc_stats_table_3[((_val.uint - 4623507967449235456ull) >> 48)] + 13;
    _bkt.dbl = grpc_stats_table_2[bucket];
    bucket -= (_val.uint < _bkt.uint);
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_TCP_READ_OFFER_IOV_SIZE, bucket);
    return;
  }
  GRPC_STATS_INC_HISTOGRAM((exec_ctx),
                           GRPC_STATS_HISTOGRAM_TCP_READ_OFFER_IOV_SIZE,
                           grpc_stats_histo_find_bucket_slow(
                               (exec_ctx), value, grpc_stats_table_2, 64));
}
void grpc_stats_inc_http2_send_message_size(grpc_exec_ctx *exec_ctx,
                                            int value) {
  value = GPR_CLAMP(value, 0, 16777216);
  if (value < 5) {
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_HTTP2_SEND_MESSAGE_SIZE, value);
    return;
  }
  union {
    double dbl;
    uint64_t uint;
  } _val, _bkt;
  _val.dbl = value;
  if (_val.uint < 4683743612465315840ull) {
    int bucket =
        grpc_stats_table_1[((_val.uint - 4617315517961601024ull) >> 50)] + 5;
    _bkt.dbl = grpc_stats_table_0[bucket];
    bucket -= (_val.uint < _bkt.uint);
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_HTTP2_SEND_MESSAGE_SIZE, bucket);
    return;
  }
  GRPC_STATS_INC_HISTOGRAM((exec_ctx),
                           GRPC_STATS_HISTOGRAM_HTTP2_SEND_MESSAGE_SIZE,
                           grpc_stats_histo_find_bucket_slow(
                               (exec_ctx), value, grpc_stats_table_0, 64));
}
void grpc_stats_inc_http2_send_initial_metadata_per_write(
    grpc_exec_ctx *exec_ctx, int value) {
  value = GPR_CLAMP(value, 0, 1024);
  if (value < 13) {
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_HTTP2_SEND_INITIAL_METADATA_PER_WRITE,
        value);
    return;
  }
  union {
    double dbl;
    uint64_t uint;
  } _val, _bkt;
  _val.dbl = value;
  if (_val.uint < 4637863191261478912ull) {
    int bucket =
        grpc_stats_table_3[((_val.uint - 4623507967449235456ull) >> 48)] + 13;
    _bkt.dbl = grpc_stats_table_2[bucket];
    bucket -= (_val.uint < _bkt.uint);
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_HTTP2_SEND_INITIAL_METADATA_PER_WRITE,
        bucket);
    return;
  }
  GRPC_STATS_INC_HISTOGRAM(
      (exec_ctx), GRPC_STATS_HISTOGRAM_HTTP2_SEND_INITIAL_METADATA_PER_WRITE,
      grpc_stats_histo_find_bucket_slow((exec_ctx), value, grpc_stats_table_2,
                                        64));
}
void grpc_stats_inc_http2_send_message_per_write(grpc_exec_ctx *exec_ctx,
                                                 int value) {
  value = GPR_CLAMP(value, 0, 1024);
  if (value < 13) {
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_HTTP2_SEND_MESSAGE_PER_WRITE, value);
    return;
  }
  union {
    double dbl;
    uint64_t uint;
  } _val, _bkt;
  _val.dbl = value;
  if (_val.uint < 4637863191261478912ull) {
    int bucket =
        grpc_stats_table_3[((_val.uint - 4623507967449235456ull) >> 48)] + 13;
    _bkt.dbl = grpc_stats_table_2[bucket];
    bucket -= (_val.uint < _bkt.uint);
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_HTTP2_SEND_MESSAGE_PER_WRITE, bucket);
    return;
  }
  GRPC_STATS_INC_HISTOGRAM((exec_ctx),
                           GRPC_STATS_HISTOGRAM_HTTP2_SEND_MESSAGE_PER_WRITE,
                           grpc_stats_histo_find_bucket_slow(
                               (exec_ctx), value, grpc_stats_table_2, 64));
}
void grpc_stats_inc_http2_send_trailing_metadata_per_write(
    grpc_exec_ctx *exec_ctx, int value) {
  value = GPR_CLAMP(value, 0, 1024);
  if (value < 13) {
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_HTTP2_SEND_TRAILING_METADATA_PER_WRITE,
        value);
    return;
  }
  union {
    double dbl;
    uint64_t uint;
  } _val, _bkt;
  _val.dbl = value;
  if (_val.uint < 4637863191261478912ull) {
    int bucket =
        grpc_stats_table_3[((_val.uint - 4623507967449235456ull) >> 48)] + 13;
    _bkt.dbl = grpc_stats_table_2[bucket];
    bucket -= (_val.uint < _bkt.uint);
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_HTTP2_SEND_TRAILING_METADATA_PER_WRITE,
        bucket);
    return;
  }
  GRPC_STATS_INC_HISTOGRAM(
      (exec_ctx), GRPC_STATS_HISTOGRAM_HTTP2_SEND_TRAILING_METADATA_PER_WRITE,
      grpc_stats_histo_find_bucket_slow((exec_ctx), value, grpc_stats_table_2,
                                        64));
}
void grpc_stats_inc_http2_send_flowctl_per_write(grpc_exec_ctx *exec_ctx,
                                                 int value) {
  value = GPR_CLAMP(value, 0, 1024);
  if (value < 13) {
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_HTTP2_SEND_FLOWCTL_PER_WRITE, value);
    return;
  }
  union {
    double dbl;
    uint64_t uint;
  } _val, _bkt;
  _val.dbl = value;
  if (_val.uint < 4637863191261478912ull) {
    int bucket =
        grpc_stats_table_3[((_val.uint - 4623507967449235456ull) >> 48)] + 13;
    _bkt.dbl = grpc_stats_table_2[bucket];
    bucket -= (_val.uint < _bkt.uint);
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_HTTP2_SEND_FLOWCTL_PER_WRITE, bucket);
    return;
  }
  GRPC_STATS_INC_HISTOGRAM((exec_ctx),
                           GRPC_STATS_HISTOGRAM_HTTP2_SEND_FLOWCTL_PER_WRITE,
                           grpc_stats_histo_find_bucket_slow(
                               (exec_ctx), value, grpc_stats_table_2, 64));
}
void grpc_stats_inc_executor_closures_per_wakeup(grpc_exec_ctx *exec_ctx,
                                                 int value) {
  value = GPR_CLAMP(value, 0, 1024);
  if (value < 13) {
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_EXECUTOR_CLOSURES_PER_WAKEUP, value);
    return;
  }
  union {
    double dbl;
    uint64_t uint;
  } _val, _bkt;
  _val.dbl = value;
  if (_val.uint < 4637863191261478912ull) {
    int bucket =
        grpc_stats_table_3[((_val.uint - 4623507967449235456ull) >> 48)] + 13;
    _bkt.dbl = grpc_stats_table_2[bucket];
    bucket -= (_val.uint < _bkt.uint);
    GRPC_STATS_INC_HISTOGRAM(
        (exec_ctx), GRPC_STATS_HISTOGRAM_EXECUTOR_CLOSURES_PER_WAKEUP, bucket);
    return;
  }
  GRPC_STATS_INC_HISTOGRAM((exec_ctx),
                           GRPC_STATS_HISTOGRAM_EXECUTOR_CLOSURES_PER_WAKEUP,
                           grpc_stats_histo_find_bucket_slow(
                               (exec_ctx), value, grpc_stats_table_2, 64));
}
void grpc_stats_inc_server_cqs_checked(grpc_exec_ctx *exec_ctx, int value) {
  value = GPR_CLAMP(value, 0, 64);
  if (value < 3) {
    GRPC_STATS_INC_HISTOGRAM((exec_ctx),
                             GRPC_STATS_HISTOGRAM_SERVER_CQS_CHECKED, value);
    return;
  }
  union {
    double dbl;
    uint64_t uint;
  } _val, _bkt;
  _val.dbl = value;
  if (_val.uint < 4625196817309499392ull) {
    int bucket =
        grpc_stats_table_5[((_val.uint - 4613937818241073152ull) >> 51)] + 3;
    _bkt.dbl = grpc_stats_table_4[bucket];
    bucket -= (_val.uint < _bkt.uint);
    GRPC_STATS_INC_HISTOGRAM((exec_ctx),
                             GRPC_STATS_HISTOGRAM_SERVER_CQS_CHECKED, bucket);
    return;
  }
  GRPC_STATS_INC_HISTOGRAM((exec_ctx), GRPC_STATS_HISTOGRAM_SERVER_CQS_CHECKED,
                           grpc_stats_histo_find_bucket_slow(
                               (exec_ctx), value, grpc_stats_table_4, 8));
}
const int grpc_stats_histo_buckets[12] = {64, 64, 64, 64, 64, 64,
                                          64, 64, 64, 64, 64, 8};
const int grpc_stats_histo_start[12] = {0,   64,  128, 192, 256, 320,
                                        384, 448, 512, 576, 640, 704};
const int *const grpc_stats_histo_bucket_boundaries[12] = {
    grpc_stats_table_0, grpc_stats_table_2, grpc_stats_table_0,
    grpc_stats_table_0, grpc_stats_table_2, grpc_stats_table_0,
    grpc_stats_table_2, grpc_stats_table_2, grpc_stats_table_2,
    grpc_stats_table_2, grpc_stats_table_2, grpc_stats_table_4};
void (*const grpc_stats_inc_histogram[12])(grpc_exec_ctx *exec_ctx, int x) = {
    grpc_stats_inc_tcp_write_size,
    grpc_stats_inc_tcp_write_iov_size,
    grpc_stats_inc_tcp_read_size,
    grpc_stats_inc_tcp_read_offer,
    grpc_stats_inc_tcp_read_offer_iov_size,
    grpc_stats_inc_http2_send_message_size,
    grpc_stats_inc_http2_send_initial_metadata_per_write,
    grpc_stats_inc_http2_send_message_per_write,
    grpc_stats_inc_http2_send_trailing_metadata_per_write,
    grpc_stats_inc_http2_send_flowctl_per_write,
    grpc_stats_inc_executor_closures_per_wakeup,
    grpc_stats_inc_server_cqs_checked};
